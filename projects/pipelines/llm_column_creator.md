---
title: "LLM Column Creator"
layout: default
---

# LLM Column Creator

**Project:** eirepolitic  
**Type:** pipeline  
**Last generated:** 2026-02-27T21:20:03.760090Z

---

## Overview

### Purpose
The "LLM Column Creator" pipeline adds new columns to existing CSV or Parquet files by generating content based on existing columns and large language models (LLMs).

### Scope
This pipeline uses a Python script (`llm_table_runner.py`) and a YAML configuration file. It reads CSV files from S3, keeps selected columns, creates up to five prompt variables, and uses the OpenAI Responses API (with optional web search) to generate new column content. It outputs results to S3 in CSV and Parquet formats.

It supports configurable write modes (`full_table` or `processed_only`) and an `overwrite_existing` flag to control whether only missing rows or all rows are processed. Output is validated for non-empty content, word count limits, and optional regex patterns. Other features include citation removal, autosaving, unique row IDs, GPT-5 family model support, and reasoning/verbosity options.

Run the script with a YAML configuration that specifies S3 details, target columns, prompt variables, output columns, prompt templates, LLM parameters, retry/delay settings, modes, overwrite behavior, and validation rules. Example YAMLs show how to add columns like "conflicts_of_interest" and "absence_reason" for Irish politicians using LLM and web search content.

## Assets

The pipeline includes these key assets:

- **Python Script**  
  - `llm_table_runner.py` at `process/llm_table_runner.py` in the GitHub repo.  
  - Reads CSV from S3, retains selected columns, creates up to five prompt variables, calls OpenAI Responses API, and writes output CSV and Parquet files to S3.  
  - Write modes:  
    - `full_table`: entire dataset with input, kept, and output columns.  
    - `processed_only`: only rows processed in current run.  
  - Overwrite:  
    - `true`: recomputes the output column for all/test rows.  
    - `false` (default): fills only missing values for resumable runs.  
  - Includes helper S3 functions and a `TaskConfig` dataclass for YAML loading.  
  - Validation for non-empty, word count, and optional regex.  
  - Autosave for incremental S3 writes.  
  - Command line argument specifies the YAML task config.

- **YAML Configuration Files**  
  - Define S3 paths, columns, IDs, prompt variables, output column, prompt template, LLM params, run mode, and validation.  
  - Example files include `tasks/llm_task_template.yml` and `tasks/Absence_Reasons.yml`, specifying S3 details, kept columns, prompt variables, and model (`gpt-4.1-mini`).

- **Output Files**  
  - Written to S3 as CSV and Parquet (Snappy compressed).

- **GitHub Actions Workflows**  
  - `.github/workflows/llm_task_controller_template.yml` and `.github/workflows/Absence_Reason_Manual.yml` allow manual runs, set AWS/OpenAI credentials, install dependencies, and run the script with a YAML config.

## Inputs and Outputs

### Inputs
The pipeline reads a CSV from S3 specified by the YAML config (`bucket`, `input_key`). Selected columns are kept (`keep_cols`). A row ID is sourced from `id_col` or generated from `id_hash_cols`. Up to five columns serve as prompt variables (`var_cols`) for filling placeholders in the prompt template.

### Outputs
A new column (`output_col`) is generated by LLM calls, validated for non-empty, word count, and optional regex. If validation fails, the LLM attempts a correction. The output column is appended and saved to S3 as CSV (`output_csv_key`) and Parquet (`output_parquet_key`). Write mode (`full_table` or `processed_only`) and the `overwrite_existing` flag control which rows are processed. Autosave and test mode (`test_rows`) are supported.

## How it works

The pipeline updates input CSV/Parquet files by adding new columns generated from other columns or LLM outputs. It is driven by a YAML config.

Input files are loaded from S3; selected columns are kept. Each row is assigned a unique ID from a specified column or hash. Existing output files are loaded if present to avoid recomputation.

Up to five variables from columns are used in the prompt template. The OpenAI Responses API is called (optionally with web search) per row to generate the new column, with optional citation removal.

Rows to process are chosen by missing output or overwrite mode. Each prompt is rendered, sent to the LLM, and the output is validated (non-empty, word count, optional regex). If invalid, a repair prompt is used.

Progress is autosaved at intervals. Output is written to S3 as CSV and Parquet. Two write modes are offered (`full_table`, `processed_only`). The script is executed via a single YAML configuration file specifying all parameters.

## How to run

Run the script `process/llm_table_runner.py` with a YAML config:

```bash
python process/llm_table_runner.py <task_config.yml>
```

### Configuration

The YAML config specifies:

- S3 bucket and file keys
- Columns to keep and ID columns
- Prompt variables and output column
- Prompt template and LLM model/settings
- Write mode and overwrite flag
- Validation rules

### Data Input and Output

- Reads input CSV from S3 (`input_key`)
- Writes output CSV and Parquet to S3 (`output_csv_key`, `output_parquet_key`)

### Write Modes and Overwrite

- `full_table`: writes all input rows with output column
- `processed_only`: writes only processed rows
- `overwrite_existing`: 
  - `true`: recomputes all rows
  - `false`: fills only missing values

### Test Mode

Limit rows processed via `test_rows` in the config.

### Environment Variables

Required:

- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`
- `OPENAI_API_KEY`

### Dependencies

Requires Python 3.11 and:

- `boto3`
- `pandas`
- `pyarrow`
- `pyyaml`
- OpenAI Python client

### Running via GitHub Actions

GitHub workflows can run the pipeline by:

- Checking out the repo
- Setting up Python 3.11
- Installing dependencies
- Optionally overriding `test_rows`
- Running the script with YAML config

### Output and Logging

The script reports:

- S3 input/output paths
- Model info
- Number of rows processed
- Autosave events
- Completion status

## Data quality and validation

Validation parameters are defined in the `validation` section of the YAML config:

- `require_non_empty` (bool): Output must not be empty, else `"empty_output"`.
- `max_words` (int): Output is clamped at this word count.
- `regex_must_match` (regex string): Output must match or fail with `"regex_failed"`.

Validation returns a success flag, failure reason, and cleaned/original text. On failure, a repair prompt is appended, and LLM is called again. If still invalid, the original output is not used.

Existing outputs are loaded to skip previously processed rows unless overwriting. Missing values (None, empty, "nan", etc.) are robustly detected.

Autosaves occur every `autosave_interval` rows. Output is written in CSV and Parquet formats using the write mode setting.

Rows are identified by an ID column or by a SHA-256 hash (24 chars) of specified columns. Overwriting fills all rows; otherwise, only missing values are populated. Defaults require non-empty output and a 2000 word limit.

## Maintenance

Configuration is via YAML, covering S3 paths, columns, IDs, prompts, output, LLM, run parameters, write mode, and validation.

Input files are read from S3; outputs are written in CSV (UTF-8) and Parquet formats. Two write modes: `full_table` (all rows) and `processed_only` (current run).

Overwrite is controlled by `overwrite_existing`. If true, all results are recomputed. If false, only missing values are filled to support resumable runs.

Row IDs are sourced or generated by hashing. Existing output files are loaded to preserve data. Only rows missing the output value are processed unless overwrite is set.

Test mode limits row count via `test_rows`. Autosave minimizes data loss.

OpenAI API calls are retried per `max_retries` and delayed per `delay_between_requests`. Validation includes non-empty, word count, and optional regex with repair attempts.

Up to five prompt variables per row can be used; citation removal and optional web search are supported.

Python dependencies: `boto3`, `pandas`, `pyarrow`, `pyyaml`, OpenAI client. Execute with:

```bash
python process/llm_table_runner.py <task_config.yml>
```

GitHub Actions workflows provide manual runs, environment setup, dependencies, and optional `test_rows` override.

## Orchestration

Orchestration relies on a YAML config that specifies all S3/file/column/LLM/run/validation parameters. The runner script (`llm_table_runner.py`) processes the table using LLM calls per config.

Input CSV is read from S3, selected columns become prompt variables. OpenAI Responses API is called (with optional web search), outputting new column content.

Write modes:

- `full_table`: all input + output columns.
- `processed_only`: only rows processed in this run.

`overwrite_existing` controls recomputation of all/test rows or filling only missing values.

Autosave is interval-based (`autosave_interval`). LLM outputs are validated (non-empty, word count, regex). If failed, a repair prompt is used. Only valid outputs are kept.

Row uniqueness is maintained with an ID column or by hashing columns. Existing outputs are loaded unless overwriting.

Retry logic is configurable (`max_retries`, `delay_between_requests`). GitHub workflows run the script, inject environment variables, and support overriding `test_rows`. Output is written to S3 as CSV and Parquet.

## Lineage

The pipeline is implemented by `llm_table_runner.py` using a YAML config specifying all file, column, and prompt details. It reads/writes S3 CSV and Parquet files.

Selected columns are kept, up to five variables are used in prompt templates, and the OpenAI API is called per row to generate a new column.

Rows have a unique ID sourced or generated from a hash. Existing outputs are loaded if present to avoid data loss.

Supports write modes (`full_table`, `processed_only`) and resume/overwrite with appropriate flags.

LLM outputs are validated; if validation fails, a repair prompt is attempted. Retry and autosave mechanisms ensure reliability.

Features include optional citation removal, test mode, configurable request delays, and support for multiple LLM models.

Python dependencies: `boto3`, `pandas`, `pyarrow`, `pyyaml`, OpenAI client. Run with:

```bash
python process/llm_table_runner.py <task_config.yml>
```

YAML task files describe all S3, columns, prompt, and validation details. The pipeline is used for use cases like adding `conflicts_of_interest` or `absence_reason` columns.

GitHub workflows provide manual or automated execution with environment variable setup.